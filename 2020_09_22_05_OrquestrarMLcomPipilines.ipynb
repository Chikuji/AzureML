{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2020-09-22-05-OrquestrarMLcomPipilines.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPko1iti2vk2ztdafczIWzB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chikuji/AzureML/blob/master/2020_09_22_05_OrquestrarMLcomPipilines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvK_TAoLuBMs",
        "colab_type": "text"
      },
      "source": [
        "# Objetivos de aprendizado\n",
        "\n",
        "- Crie um pipeline do Azure Machine Learning.\n",
        "-Publique um pipeline do Azure Machine Learning.\n",
        "-Agende um pipeline do Azure Machine Learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EChMJbJ4wzU7",
        "colab_type": "text"
      },
      "source": [
        "# Tipos de passo\n",
        "\n",
        "- PythonScriptStep : executa um script Python especificado.\n",
        "-EstimatorStep : executa um estimador.\n",
        "-DataTransferStep : usa o Azure Data Factory para copiar dados entre armazenamentos de dados.\n",
        "-DatabricksStep : executa um bloco de notas, script ou JAR compilado em um cluster de databricks.\n",
        "-AdlaStep : executa um trabalho U-SQL no Azure Data Lake Analytics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EyaVDFmw6Mi",
        "colab_type": "text"
      },
      "source": [
        "Definição de etapas em um pipeline\n",
        "\n",
        "Para criar um pipeline, você deve primeiro definir cada etapa e, em seguida, criar um pipeline que inclua as etapas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qj3-5Q0dxqT5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Criando as etapas\n",
        "\n",
        "from azureml.pipeline.steps import PythonScriptStep, EstimatorStep\n",
        "\n",
        "# Step to run a Python script\n",
        "step1 = PythonScriptStep(name = 'prepare data',\n",
        "                         source_directory = 'scripts',\n",
        "                         script_name = 'data_prep.py',\n",
        "                         compute_target = 'aml-cluster',\n",
        "                         runconfig = run_config)\n",
        "\n",
        "# Step to run an estimator\n",
        "step2 = EstimatorStep(name = 'train model',\n",
        "                      estimator = sk_estimator,\n",
        "                      compute_target = 'aml-cluster')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_NEdEYBxvU3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Atribuindo as etapas a um pipiline\n",
        "\n",
        "from azureml.pipeline.core import Pipeline\n",
        "from azureml.core import Experiment\n",
        "\n",
        "# Construct the pipeline\n",
        "train_pipeline = Pipeline(workspace = ws, steps = [step1,step2])\n",
        "\n",
        "# Create an experiment and run the pipeline\n",
        "experiment = Experiment(workspace = ws, name = 'training-pipeline')\n",
        "pipeline_run = experiment.submit(train_pipeline)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNAdCbvUyzbt",
        "colab_type": "text"
      },
      "source": [
        "O objeto PipelineData\n",
        "\n",
        "Para usar um objeto PipelineData para passar dados entre as etapas, você deve:\n",
        "\n",
        "1. Defina um objeto PipelineData nomeado que faz referência a um local em um armazenamento de dados.\n",
        "2. Especifique o objeto PipelineData como uma entrada ou saída para as etapas que o utilizam.\n",
        "3. Passe o objeto PipelineData como um parâmetro de script nas etapas que executam scripts (e inclua o código nesses scripts para ler ou gravar dados)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWeX2428yz8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from azureml.pipeline.core import PipelineData\n",
        "from azureml.pipeline.steps import PythonScriptStep, EstimatorStep\n",
        "\n",
        "# Get a dataset for the initial data\n",
        "raw_ds = Dataset.get_by_name(ws, 'raw_dataset')\n",
        "\n",
        "# Define a PipelineData object to pass data between steps\n",
        "data_store = ws.get_default_datastore()\n",
        "prepped_data = PipelineData('prepped',  datastore=data_store)\n",
        "\n",
        "# Step to run a Python script\n",
        "step1 = PythonScriptStep(name = 'prepare data',\n",
        "                         source_directory = 'scripts',\n",
        "                         script_name = 'data_prep.py',\n",
        "                         compute_target = 'aml-cluster',\n",
        "                         runconfig = run_config,\n",
        "                         # Specify dataset as initial input\n",
        "                         inputs=[raw_ds.as_named_input('raw_data')],\n",
        "                         # Specify PipelineData as output\n",
        "                         outputs=[prepped_data],\n",
        "                         # Also pass as data reference to script\n",
        "                         arguments = ['--folder', prepped_data])\n",
        "\n",
        "# Step to run an estimator\n",
        "step2 = EstimatorStep(name = 'train model',\n",
        "                      estimator = sk_estimator,\n",
        "                      compute_target = 'aml-cluster',\n",
        "                      # Specify PipelineData as input\n",
        "                      inputs=[prepped_data],\n",
        "                      # Pass as data reference to estimator script\n",
        "                      estimator_entry_script_arguments=['--folder', prepped_data])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mctjrm8ezf_h",
        "colab_type": "text"
      },
      "source": [
        "Nos próprios scripts, você pode obter uma referência ao objeto PipelineData do argumento do script e usá-lo como uma pasta local."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wW7NajY6zhkb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# code in data_prep.py\n",
        "from azureml.core import Run\n",
        "import argparse\n",
        "import os\n",
        "\n",
        "# Get the experiment run context\n",
        "run = Run.get_context()\n",
        "\n",
        "# Get input dataset as dataframe\n",
        "raw_df = run.input_datasets['raw_data'].to_pandas_dataframe()\n",
        "\n",
        "# Get PipelineData argument\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--folder', type=str, dest='folder')\n",
        "args = parser.parse_args()\n",
        "output_folder = args.folder\n",
        "\n",
        "# code to prep data (in this case, just select specific columns)\n",
        "prepped_df = raw_df[['col1', 'col2', 'col3']]\n",
        "\n",
        "# Save prepped data to the PipelineData location\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "output_path = os.path.join(output_folder, 'prepped_data.csv')\n",
        "prepped_df.to_csv(output_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2z8WvmTv0YaS",
        "colab_type": "text"
      },
      "source": [
        "# Gerenciando a reutilização da saída da etapa\n",
        "\n",
        "Para controlar a reutilização de uma etapa individual, você pode definir o parâmetro allow_reuse na configuração da etapa, assim:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaQrkbMS0bpA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "step1 = PythonScriptStep(name = 'prepare data',\n",
        "                         source_directory = 'scripts',\n",
        "                         script_name = 'data_prep.py',\n",
        "                         compute_target = 'aml-cluster',\n",
        "                         runconfig = run_config,\n",
        "                         inputs=[raw_ds.as_named_input('raw_data')],\n",
        "                         outputs=[prepped_data],\n",
        "                         arguments = ['--folder', prepped_data]),\n",
        "                         # Disable step reuse\n",
        "                         allow_reuse = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fSH5eBb0dYp",
        "colab_type": "text"
      },
      "source": [
        "Forçando todas as etapas a correr"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oNdUWQ60eow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipeline_run = experiment.submit(train_pipeline, regenerate_outputs=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6FJXR0j1Cls",
        "colab_type": "text"
      },
      "source": [
        "# Publicar um pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XU1EQa451TS_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "published_pipeline = pipeline.publish(name='training_pipeline',\n",
        "                                          description='Model training pipeline',\n",
        "                                          version='1.0')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOXZQR6w1Usn",
        "colab_type": "text"
      },
      "source": [
        "Como alternativa, você pode chamar o método de publicação em uma execução bem-sucedida do pipeline:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-G-pg9BU1WPu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the most recent run of the pipeline\n",
        "pipeline_experiment = ws.experiments.get('training-pipeline')\n",
        "run = list(pipeline_experiment.get_runs())[0]\n",
        "\n",
        "# Publish the pipeline from the run\n",
        "published_pipeline = run.publish_pipeline(name='training_pipeline',\n",
        "                                          description='Model training pipeline',\n",
        "                                          version='1.0')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AKth0pe1aBo",
        "colab_type": "text"
      },
      "source": [
        "Após a publicação do pipeline, você pode exibi-lo no Azure Machine Learning Studio. Você também pode determinar o URI de seu ponto de extremidade desta forma:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0zX3eDF1Zmb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rest_endpoint = published_pipeline.endpoint\n",
        "print(rest_endpoint)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSj0Q4G41vOH",
        "colab_type": "text"
      },
      "source": [
        "# Usando um pipeline publicado\n",
        "\n",
        "Por exemplo, o código Python a seguir faz uma solicitação REST para executar um pipeline e exibe o ID de execução retornado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PITRUCR1zDa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "\n",
        "response = requests.post(rest_endpoint,\n",
        "                         headers=auth_header,\n",
        "                         json={\"ExperimentName\": \"run_training_pipeline\"})\n",
        "run_id = response.json()[\"Id\"]\n",
        "print(run_id)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}